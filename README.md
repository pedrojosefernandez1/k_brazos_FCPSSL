# ğŸ¤– Bandido de K-Brazos
## â„¹ï¸ InformaciÃ³n
- **Alumnos:** Sendra LÃ¡zaro, Ricardo Javier; Pujante SÃ¡ez, Jaime; FernÃ¡ndez Campillo, Pedro JosÃ©;
- **Asignatura:** Extensiones de Machine Learning
- **Curso:** 2024/2025
- **Grupo:** FCPSSL

## ğŸ“– DescripciÃ³n
Este proyecto analiza el problema del **Bandido de K-Brazos**, un escenario de **aprendizaje por refuerzo** en el que un agente debe seleccionar entre **K opciones** para maximizar su recompensa acumulada. Se estudian y comparan diferentes algoritmos en entornos **estacionarios**, evaluando su desempeÃ±o en tÃ©rminos de **recompensas promedio** y **regret acumulado**.

Para ello, se han implementado varias estrategias de toma de decisiones:
- **ğœ€-Greedy**: Una de las estrategias mÃ¡s simples, que equilibra exploraciÃ³n y explotaciÃ³n.
- **Upper Confidence Bound (UCB)**: Un enfoque basado en el optimismo ante la incertidumbre.
- **Ascenso de Gradiente**: MÃ©todos como **Softmax** y **Gradiente de Preferencias** que ajustan dinÃ¡micamente la probabilidad de selecciÃ³n de cada brazo.

## ğŸ“‚ Estructura del Repositorio

El repositorio estÃ¡ organizado en los siguientes notebooks:

- **`introduccion.ipynb`**: ExplicaciÃ³n teÃ³rica del problema y enlaces a los estudios especÃ­ficos.
- **`UCB.ipynb`**: ImplementaciÃ³n y anÃ¡lisis del mÃ©todo **Upper Confidence Bound**.
- **`ascensoGradiente.ipynb`**: Estudio de los mÃ©todos de **Softmax** y **Gradiente de Preferencias**.
- **`epsilonGreedy.ipynb`**: EvaluaciÃ³n de la estrategia **ğœ€-Greedy**.

AdemÃ¡s, el cÃ³digo fuente se encuentra dentro del directorio `src/`, con la siguiente estructura:

```
â”‚â”€â”€ src/
â”‚   â”‚â”€â”€ algorithms/
â”‚   â”‚   â”‚â”€â”€ UCB1
â”‚   â”‚   â”‚â”€â”€ UCB2
â”‚   â”‚   â”‚â”€â”€ EpsilonGreedy
â”‚   â”‚   â”‚â”€â”€ Softmax
â”‚   â”‚   â””â”€â”€ GradientePreferencias
â”‚   â”‚â”€â”€ arms/
â”‚   â”‚   â”‚â”€â”€ Bernoulli
â”‚   â”‚   â”‚â”€â”€ Normal
â”‚   â”‚   â””â”€â”€ Binomial
â”‚   â”‚â”€â”€ experiments/
â”‚   â””â”€â”€ plotting/
â”‚â”€â”€ docs/
```

- **`src/algorithms/`**: ImplementaciÃ³n de los mÃ©todos de decisiÃ³n:
  - `UCB1`, `UCB2`
  - `EpsilonGreedy`
  - `Softmax`
  - `GradientePreferencias`

- **`src/arms/`**: ImplementaciÃ³n de los modelos de recompensa:
  - `Bernoulli`
  - `Normal`
  - `Binomial`

- **`src/experiments/`**: CÃ³digo para la ejecuciÃ³n de simulaciones y evaluaciÃ³n de los algoritmos.

- **`src/plotting/`**: Funciones para la visualizaciÃ³n de resultados, incluyendo grÃ¡ficos de recompensas, regret acumulado y selecciÃ³n de brazos.

- **`docs/`**: DocumentaciÃ³n detallada del proyecto.



## â–¶ï¸ EjecuciÃ³n
Para ejecutar los notebooks en Google Colab:
Dirigirse primero de todo al notebook **`main.ipynb`** donde se podrÃ¡ acceder a cualquier notebook que se encuentra en el repositorio de una manera interactiva. PodrÃ­a seleccionar **`introduccion.ipynb`** para ver una breve introducciÃ³n al problema y enlace a los demÃ¡s estudios.

**Abre y ejecuta los notebooks** en Google Colab o Jupyter Notebook.

## ğŸ› ï¸ TecnologÃ­as Utilizadas
El proyecto estÃ¡ desarrollado con:
- **Python 3.11**
- **NumPy, Matplotlib, Seaborn** para cÃ¡lculos y visualizaciÃ³n de datos.
- **Google Colab** para la ejecuciÃ³n interactiva.
